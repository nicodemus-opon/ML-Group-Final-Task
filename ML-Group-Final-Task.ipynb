{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b701fe82-d3cb-4af6-ab0e-9d2e44b369a8",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "[https://www.kaggle.com/praveengovi/emotions-dataset-for-nlp](https://www.kaggle.com/praveengovi/emotions-dataset-for-nlp)\n",
    "\n",
    "predict feeling when provided with a text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb31e35e-7109-474e-85c7-8a6bc79d3057",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f8bfdb-e9b1-4fd7-9084-583dc18c5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from numpy import zeros\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.core import Activation, Dropout, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dbabba-c0a9-4566-ba76-3b5519b26c77",
   "metadata": {},
   "source": [
    "### join datasets\n",
    "> the dataset was already split into train,test,validation...this block joins the datasets into a single dataset so that the dataset split can be carried out later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4e92c1d-f646-4402-beda-937e370c7951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>feeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>im having ssa examination tomorrow in the morn...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>i constantly worry about their fight against n...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>i feel its important to share this info for th...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>i truly feel that if you are passionate enough...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>i feel like i just wanna buy any cute make up ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  feeling\n",
       "19992  im having ssa examination tomorrow in the morn...  sadness\n",
       "19993  i constantly worry about their fight against n...      joy\n",
       "19994  i feel its important to share this info for th...      joy\n",
       "19995  i truly feel that if you are passionate enough...      joy\n",
       "19996  i feel like i just wanna buy any cute make up ...      joy"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#column names\n",
    "labels=[\"text\",\"feeling\"]\n",
    "# read datasets\n",
    "chunk1=pd.read_csv(\"data/test.txt\",delimiter=\";\",names=labels,skiprows=1)\n",
    "chunk2=pd.read_csv(\"data/train.txt\",delimiter=\";\",names=labels,skiprows=1)\n",
    "chunk3=pd.read_csv(\"data/val.txt\",delimiter=\";\",names=labels,skiprows=1)\n",
    "\n",
    "# join datasets\n",
    "data=pd.concat([chunk1,chunk2,chunk3], axis=0)\n",
    "\n",
    "# reset index since concatinating keeps the orginal index of the datasets\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1cd74c-1531-411f-853b-95363d6b8cb5",
   "metadata": {},
   "source": [
    "### preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6cce8e-cde8-4b59-87f0-d5f6b0c131b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>feeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>updating my blog because   shitty</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>never make her separate from me because  don ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>left with my bouquet of red and yellow tulips...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>was  a little vain when  did this one</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cant walk into a shop anywhere where  do not ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  feeling\n",
       "0                  updating my blog because   shitty  sadness\n",
       "1   never make her separate from me because  don ...  sadness\n",
       "2   left with my bouquet of red and yellow tulips...      joy\n",
       "3              was  a little vain when  did this one  sadness\n",
       "4   cant walk into a shop anywhere where  do not ...     fear"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning\n",
    "# all text to lower case\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "# removing common words - noise\n",
    "x_words=[\"i \",\"im \",\"feel \",\"feeling \"]\n",
    "for x_word in x_words:\n",
    "    data['text'] = data['text'].apply(lambda x: x.replace(x_word, ' '))\n",
    "# preview cleaned data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e59086de-bc21-434e-8c2e-0ec426ad2d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>feeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>having ssa examination tomorrow in the mornin...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>constantly worry about their fight against na...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>its important to share this info for those t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>truly  that if you are passionate enough abou...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>like  just wanna buy any cute make up  see o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  feeling\n",
       "19992   having ssa examination tomorrow in the mornin...        4\n",
       "19993   constantly worry about their fight against na...        2\n",
       "19994    its important to share this info for those t...        2\n",
       "19995   truly  that if you are passionate enough abou...        2\n",
       "19996    like  just wanna buy any cute make up  see o...        2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding\n",
    "\n",
    "tmp_ct=data[\"feeling\"].astype(\"category\")\n",
    "data[\"feeling\"] = tmp_ct.cat.codes\n",
    "\n",
    "# used to refer to the category codes\n",
    "# i.e {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}\n",
    "category_map=dict(enumerate(tmp_ct.cat.categories))\n",
    "\n",
    "# preview encoded data\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee233348-b7c2-48b4-a461-d7b9318ab4c0",
   "metadata": {},
   "source": [
    "### train test validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93eae5ae-77e8-4dde-a05f-12c5fd58b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[\"text\"]\n",
    "y=data[\"feeling\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8765fc39-1612-4ebf-ae29-0d0e28ec472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "max_words = 5000\n",
    "tokenizer=Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "seq= tokenizer.texts_to_sequences(X_train.values)\n",
    "seq_val = tokenizer.texts_to_sequences(X_val.values)\n",
    "X_train_seq = pad_sequences(seq,maxlen=max_len)\n",
    "X_val_seq = pad_sequences(seq_val,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b018191-d231-4918-9382-28b1ff39039f",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f83f73b-f89d-4fb9-ab2c-cb2de43bfa89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 100)          1398500   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,479,001\n",
      "Trainable params: 80,501\n",
      "Non-trainable params: 1,398,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - 30s 262ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 29s 270ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 26s 242ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 25s 233ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 22s 206ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 23s 215ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 26s 241ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 22s 205ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 24s 222ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 23s 214ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 24s 227ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 24s 226ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 26s 246ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 27s 255ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 23s 212ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 26s 244ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 25s 238ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - 38s 354ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - 30s 283ms/step - loss: 0.0000e+00 - accuracy: 0.1188 - val_loss: 0.0000e+00 - val_accuracy: 0.1191\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100,input_length=100,trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(100,dropout=0.2))\n",
    "model.add(Dense(1,activation='softmax'))\n",
    "\n",
    "# tracking accuracy\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "history = model.fit(np.array(X_train_seq), np.array(y_train), epochs=20, verbose=1,batch_size = 128,validation_data=(X_val_seq,y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
